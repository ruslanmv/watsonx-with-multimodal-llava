{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruslanmv/watsonx-with-multimodal-llava/blob/master/6_Watsonx_Multimodal_Chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hotel Recommendation with Multimodal and WatsonX\n",
        "#### Developed by Ruslan Magana"
      ],
      "metadata": {
        "id": "v7fv4YX8H5BX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWAeulaTwsW0",
        "outputId": "14cf8e90-1715-4609-8be1-0d0c2211b95b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-uif_25q2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-uif_25q2\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 20a04497a86dc79adb8a93e31325f25255d317e1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.4.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2024.7.4)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.45.0.dev0-py3-none-any.whl size=9530986 sha256=79480e09ff6e44b18a8d1f38a2774c0b9695002884600358af50a2186f1ce0b8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-stjodp6v/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "Successfully installed transformers-4.45.0.dev0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.4.1\n",
            "Collecting gradio_multimodalchatbot\n",
            "  Downloading gradio_multimodalchatbot-0.0.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting gradio<5.0,>=4.0 (from gradio_multimodalchatbot)\n",
            "  Downloading gradio-4.41.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (3.7.1)\n",
            "Collecting fastapi (from gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading fastapi-0.112.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (2.8.2)\n",
            "Collecting pydub (from gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio_multimodalchatbot) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0,>=4.0->gradio_multimodalchatbot) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio<5.0,>=4.0->gradio_multimodalchatbot) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio<5.0,>=4.0->gradio_multimodalchatbot) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio<5.0,>=4.0->gradio_multimodalchatbot) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0,>=4.0->gradio_multimodalchatbot) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0,>=4.0->gradio_multimodalchatbot) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0,>=4.0->gradio_multimodalchatbot) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio<5.0,>=4.0->gradio_multimodalchatbot)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio<5.0,>=4.0->gradio_multimodalchatbot) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0,>=4.0->gradio_multimodalchatbot) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0,>=4.0->gradio_multimodalchatbot) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio<5.0,>=4.0->gradio_multimodalchatbot) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0,>=4.0->gradio_multimodalchatbot) (0.1.2)\n",
            "Downloading gradio_multimodalchatbot-0.0.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.41.0-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio, gradio_multimodalchatbot\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.0\n",
            "    Uninstalling tomlkit-0.13.0:\n",
            "      Successfully uninstalled tomlkit-0.13.0\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.112.0 ffmpy-0.4.0 gradio-4.41.0 gradio-client-1.3.0 gradio_multimodalchatbot-0.0.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.9 ruff-0.5.7 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 uvicorn-0.30.6 websockets-12.0\n",
            "Collecting haversine\n",
            "  Downloading haversine-2.8.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Downloading haversine-2.8.1-py2.py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: haversine\n",
            "Successfully installed haversine-2.8.1\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.13-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.30 (from langchain)\n",
            "  Downloading langchain_core-0.2.30-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.99-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.30->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading langchain-0.2.13-py3-none-any.whl (997 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.30-py3-none-any.whl (384 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.8/384.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.99-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: tenacity, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.13 langchain-core-0.2.30 langchain-text-splitters-0.2.2 langsmith-0.1.99 tenacity-8.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade -q accelerate bitsandbytes\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install datasets\n",
        "!pip install gradio_multimodalchatbot\n",
        "!pip install haversine\n",
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install langchain_ibm\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from gradio_multimodalchatbot import MultimodalChatbot\n",
        "from gradio.data_classes import FileData\n",
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib3\n",
        "from transformers import pipeline\n",
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "import textwrap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from haversine import haversine  # Install haversine library: pip install haversine\n",
        "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "from huggingface_hub import InferenceClient\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoImageProcessor\n",
        "from datasets import load_dataset\n",
        "from geopy.geocoders import Nominatim\n",
        "import pyarrow\n",
        "from dotenv import load_dotenv\n",
        "from os import environ, getenv\n",
        "from getpass import getpass\n",
        "from pydantic import BaseModel\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_ibm import WatsonxLLM"
      ],
      "metadata": {
        "id": "5dpAkYpKdPjr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Function to set environment variables\n",
        "def set_env(var: str):\n",
        "    env_var = getenv(var)\n",
        "    if not env_var:\n",
        "        env_var = getpass(f\"{var}: \")\n",
        "        environ[var] = env_var\n",
        "    return env_var\n",
        "\n",
        "# Define IBM connection parameters\n",
        "class IbmConnectionParams(BaseModel):\n",
        "    api_key: str\n",
        "    project_id: str\n",
        "    url: str\n",
        "    credentials: dict[str, str]\n",
        "\n",
        "    def __init__(self, api_key: str, project_id: str, url: str) -> None:\n",
        "        super().__init__(api_key=api_key, project_id=project_id, url=url, credentials={\"url\": url, \"apikey\": api_key})\n",
        "\n",
        "# Load IBM connection parameters from environment variables\n",
        "def load_connection_params() -> IbmConnectionParams:\n",
        "    api_key = set_env(\"WATSONX_API_KEY\")\n",
        "    project_id = set_env(\"PROJECT_ID\")\n",
        "    url = set_env(\"WATSONX_URL\")\n",
        "\n",
        "    return IbmConnectionParams(api_key=api_key, project_id=project_id, url=url)\n",
        "\n",
        "connection_params: IbmConnectionParams = load_connection_params()\n",
        "\n",
        "\n",
        "# Define parameters for the model\n",
        "parameters = {\n",
        "    \"decoding_method\": \"sample\",\n",
        "    \"max_new_tokens\": 300,\n",
        "    \"min_new_tokens\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_k\": 50,\n",
        "    \"top_p\": 1,\n",
        "}\n",
        "\n",
        "# Initialize the WatsonxLLM model\n",
        "watsonx_llm = WatsonxLLM(\n",
        "    model_id=\"meta-llama/llama-3-70b-instruct\",\n",
        "    apikey=connection_params.api_key,\n",
        "    url=connection_params.url,\n",
        "    project_id=connection_params.project_id,\n",
        "    params=parameters,\n",
        ")\n",
        "#watsonx_llm.invoke(\"What is the capital of Italy?\")\n",
        "\n",
        "\n",
        "# Ensure data files are available\n",
        "current_directory = os.getcwd()\n",
        "geocoded_hotels_path = os.path.join(current_directory, 'geocoded_hotels.csv')\n",
        "csv_file_path = os.path.join(current_directory, 'hotel_multimodal.csv')\n",
        "\n",
        "# Load geocoded hotels data\n",
        "if not os.path.isfile(geocoded_hotels_path):\n",
        "    url = 'https://github.com/ruslanmv/watsonx-with-multimodal-llava/raw/master/geocoded_hotels.csv'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        with open(geocoded_hotels_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"File {geocoded_hotels_path} downloaded successfully!\")\n",
        "    else:\n",
        "        print(f\"Error downloading file. Status code: {response.status_code}\")\n",
        "else:\n",
        "    print(f\"File {geocoded_hotels_path} already exists.\")\n",
        "geocoded_hotels = pd.read_csv(geocoded_hotels_path)\n",
        "\n",
        "# Load hotel dataset\n",
        "if not os.path.exists(csv_file_path):\n",
        "    dataset = load_dataset(\"ruslanmv/hotel-multimodal\")\n",
        "    df_hotels = dataset['train'].to_pandas()\n",
        "    df_hotels.to_csv(csv_file_path, index=False)\n",
        "    print(\"Dataset downloaded and saved as CSV.\")\n",
        "else:\n",
        "    df_hotels = pd.read_csv(csv_file_path)\n",
        "\n",
        "def get_current_location():\n",
        "    try:\n",
        "        response = requests.get('https://ipinfo.io/json')\n",
        "        data = response.json()\n",
        "        location = data.get('loc', '')\n",
        "        if location:\n",
        "            return map(float, location.split(','))\n",
        "        else:\n",
        "            return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def get_coordinates(location_name):\n",
        "    geolocator = Nominatim(user_agent=\"coordinate_finder\")\n",
        "    location = geolocator.geocode(location_name)\n",
        "    if location:\n",
        "        return location.latitude, location.longitude\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def find_nearby(place=None):\n",
        "    if place:\n",
        "        coordinates = get_coordinates(place)\n",
        "        if coordinates:\n",
        "            latitude, longitude = coordinates\n",
        "            print(f\"The coordinates of {place} are: Latitude: {latitude}, Longitude: {longitude}\")\n",
        "        else:\n",
        "            print(f\"Location not found: {place}\")\n",
        "            return None\n",
        "    else:\n",
        "        latitude, longitude = get_current_location()\n",
        "        if not latitude or not longitude:\n",
        "            print(\"Could not retrieve the current location.\")\n",
        "            return None\n",
        "\n",
        "    geocoded_hotels['distance_km'] = geocoded_hotels.apply(\n",
        "        lambda row: haversine((latitude, longitude), (row['latitude'], row['longitude'])),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    closest_hotels = geocoded_hotels.sort_values(by='distance_km').head(5)\n",
        "    print(\"The 5 closest locations are:\\n\")\n",
        "    print(closest_hotels)\n",
        "    return closest_hotels\n",
        "\n",
        "# Suppress InsecureRequestWarning\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "# Define the respond function\n",
        "def search_hotel(place=None):\n",
        "    df_found = find_nearby(place)\n",
        "    if df_found is None:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    hotel_ids = df_found[\"hotel_id\"].values.tolist()\n",
        "    filtered_df = df_hotels[df_hotels['hotel_id'].isin(hotel_ids)]\n",
        "\n",
        "    filtered_df.loc[:, 'hotel_id'] = pd.Categorical(filtered_df['hotel_id'], categories=hotel_ids, ordered=True)\n",
        "    filtered_df = filtered_df.sort_values('hotel_id').reset_index(drop=True)\n",
        "    grouped_df = filtered_df.groupby('hotel_id', observed=True).head(2)\n",
        "    description_data = []\n",
        "\n",
        "    for index, row in grouped_df.iterrows():\n",
        "        hotel_id = row['hotel_id']\n",
        "        hotel_name = row['hotel_name']\n",
        "        image_url = row['image_url']\n",
        "\n",
        "        try:\n",
        "            response = requests.get(image_url, verify=False)\n",
        "            response.raise_for_status()\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "            prompt = \"USER: <image>\\nAnalyze this image. Give me feedback on whether this hotel is worth visiting based on the picture. Provide a summary review.\\nASSISTANT:\"\n",
        "            outputs = pipe_image_to_text(img, prompt=prompt, generate_kwargs={\"max_new_tokens\": 200})\n",
        "            description = outputs[0][\"generated_text\"].split(\"\\nASSISTANT:\")[-1].strip()\n",
        "            description_data.append({'hotel_name': hotel_name, 'hotel_id': hotel_id, 'image': img, 'description': description})\n",
        "        except (requests.RequestException, UnidentifiedImageError):\n",
        "            print(f\"Skipping image at URL: {image_url}\")\n",
        "\n",
        "    return pd.DataFrame(description_data)\n",
        "\n",
        "# Constants\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LOW_MEMORY = os.getenv(\"LOW_MEMORY\", \"0\") == \"1\"\n",
        "MODEL_ID = \"llava-hf/llava-1.5-7b-hf\"\n",
        "\n",
        "\n",
        "# Print device and memory info\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"Low memory: {LOW_MEMORY}\")\n",
        "\n",
        "# Quantization configuration for efficient model loading\n",
        "# Define BitsAndBytesConfig\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Load the tokenizer associated with your 'MODEL_ID'\n",
        "tokenizer_image_to_text = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "# Load the image processor associated with your 'MODEL_ID'\n",
        "image_processor = AutoImageProcessor.from_pretrained(MODEL_ID)\n",
        "# Load models only once\n",
        "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
        "model = LlavaForConditionalGeneration.from_pretrained(MODEL_ID, quantization_config=quantization_config, device_map=\"auto\")\n",
        "# Pass the tokenizer, image processor explicitly to the pipeline\n",
        "pipe_image_to_text = pipeline(\"image-to-text\", model=model, tokenizer=tokenizer_image_to_text, image_processor=image_processor, model_kwargs={\"quantization_config\": quantization_config})\n",
        "\n",
        "\n",
        "def multimodal_results(description_df):\n",
        "    conversation = []\n",
        "    for _, row in description_df.iterrows():\n",
        "        hotel_name = row['hotel_name']\n",
        "        description = row['description']\n",
        "        img = row['image']\n",
        "\n",
        "        img_path = f\"{hotel_name}.png\"\n",
        "        img.save(img_path)\n",
        "\n",
        "        bot_msg = {\n",
        "            \"text\": f\"Here is {hotel_name}. {description}\",\n",
        "            \"files\": [{\"file\": FileData(path=img_path)}]\n",
        "        }\n",
        "\n",
        "        conversation.append([{\"text\": \"\", \"files\": []}, bot_msg])\n",
        "\n",
        "    return conversation\n",
        "\n",
        "\n",
        "#user_input=\"Genova Italy\"\n",
        "#description_df = search_hotel(user_input)\n",
        "#hotel_conversation = multimodal_results(description_df)\n",
        "\n",
        "def grouped_description(description_df):\n",
        "    grouped_descriptions = description_df.groupby('hotel_id')['description'].apply(lambda x: ' '.join(x.astype(str))).reset_index()\n",
        "    result_df = pd.merge(grouped_descriptions, description_df[['hotel_id', 'hotel_name']], on='hotel_id', how='left')\n",
        "    result_df = result_df.drop_duplicates(subset='hotel_id', keep='first')\n",
        "    result_df = result_df[['hotel_name', 'hotel_id', 'description']]\n",
        "    return result_df\n",
        "\n",
        "def create_prompt_result(result_df):\n",
        "    prompt = \"\"\n",
        "    for _, row in result_df.iterrows():\n",
        "        hotel_name = row['hotel_name']\n",
        "        hotel_id = row['hotel_id']\n",
        "        description = row['description']\n",
        "        prompt += f\"Hotel Name: {hotel_name}\\nHotel ID: {hotel_id}\\nDescription: {description}\\n\\n\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "\n",
        "def build_prompt(context_result):\n",
        "    hotel_recommendation_template = \"\"\"\n",
        "<s>[INST] <<SYS>>\n",
        "You are a helpful and informative chatbot assistant.\n",
        "<</SYS>>\n",
        "Based on the following hotel descriptions, recommend the best hotel:\n",
        "{context_result}\n",
        "[/INST]\n",
        "\"\"\"\n",
        "    return hotel_recommendation_template.format(context_result=context_result)\n",
        "# Define the respond function using WatsonxLLM\n",
        "def generate_text_response(prompt):\n",
        "    response = watsonx_llm.invoke(prompt)\n",
        "    return response\n",
        "\n",
        "\n",
        "def llm_results(description_df):\n",
        "    result_df = grouped_description(description_df)\n",
        "    context_result = create_prompt_result(result_df)\n",
        "    recommendation_prompt = build_prompt(context_result)\n",
        "    result = generate_text_response(recommendation_prompt)\n",
        "    conversation = [[{\"text\": \"Based on your search...\", \"files\": []}, {\"text\": f\"**My recommendation:** {result}\", \"files\": []}]]\n",
        "    return conversation\n",
        "\n",
        "#final_recommendation = llm_results(description_df)\n",
        "#final_recommendation\n",
        "\n",
        "def chatbot_response(user_input, conversation):\n",
        "    bot_initial_message = {\n",
        "        \"text\": f\"Looking for hotels in {user_input}...\",\n",
        "        \"files\": []\n",
        "    }\n",
        "    conversation.append([{\"text\": user_input, \"files\": []}, bot_initial_message])\n",
        "\n",
        "    yield conversation\n",
        "\n",
        "    description_df = search_hotel(user_input)\n",
        "\n",
        "    if description_df is None or description_df.empty:\n",
        "        error_message = {\"text\": f\"Sorry, I couldn't find any hotels for {user_input}. Please try another location.\", \"files\": []}\n",
        "        conversation.append([{\"text\": user_input, \"files\": []}, error_message])\n",
        "        yield conversation\n",
        "        return  # Exit the function early\n",
        "\n",
        "    hotel_conversation = multimodal_results(description_df)\n",
        "\n",
        "    for message_pair in hotel_conversation:\n",
        "        conversation.append(message_pair)\n",
        "        yield conversation\n",
        "\n",
        "    final_recommendation = llm_results(description_df)\n",
        "    for message_pair in final_recommendation:\n",
        "        conversation.append(message_pair)\n",
        "        yield conversation\n",
        "\n",
        "def initial_conversation():\n",
        "    return [[\n",
        "           {\"text\": \"**Welcome to Hotel Recommendation!**\", \"files\": []},\n",
        "           {\"text\": \"Please enter the place you're interested in visiting.\", \"files\": []}\n",
        "           ]]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "7d0e85e3008f4c8bb99c846ec46f617d",
            "4f652beffd4c4fa6b244ee9c3191d7d8",
            "a600dbd9b9c64c5abc8ae55f8b199aba",
            "3925d9e177b84b65b585d211bfe1bd11",
            "3b88434581724df19cbb00d9a6bda81f",
            "4215e47d272d420aab7945db0597554f",
            "a41e73ca1d784a11b296be4715b4a4fe",
            "98ea48888c2f4ee392864cd47ed39a9a",
            "4def96e841f94ba3b7e9620af6c31459",
            "51d97bd0273a45318d4dafed06a7a440",
            "c48793cdfe6e4700a6c29b5d92526967"
          ]
        },
        "id": "y2dknANFeZ7k",
        "outputId": "3f96f5f9-aa92-4b9a-f0f6-6125e725f3a5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File /content/geocoded_hotels.csv already exists.\n",
            "Using device: cuda\n",
            "Low memory: False\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d0e85e3008f4c8bb99c846ec46f617d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 🏨 WatsonX Hotel Recommendation with Multimodal  🏨\")\n",
        "    gr.Markdown(\"**Provide the location to discover hotels and receive personalized recommendations!**\")\n",
        "\n",
        "    initial_conv = initial_conversation()\n",
        "    chatbot = MultimodalChatbot(value=initial_conv, height=600)\n",
        "\n",
        "    with gr.Row():\n",
        "        place_input = gr.Textbox(label=\"Enter a place\", placeholder=\"E.g., Paris France, Tokyo Japan, Genova Italy\")\n",
        "        send_btn = gr.Button(\"Search Hotels\")\n",
        "\n",
        "    send_btn.click(chatbot_response, inputs=[place_input, chatbot], outputs=chatbot)\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zDw9AUSd1h7e",
        "outputId": "72a4cd7b-834a-47c4-882d-f44cb8cdc661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://392000e9ca8f95ffe1.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://392000e9ca8f95ffe1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The coordinates of Genova Italy are: Latitude: 44.40726, Longitude: 8.9338624\n",
            "The 5 closest locations are:\n",
            "\n",
            "       hotel_id                    hotel_name  chain_id  latitude  longitude  \\\n",
            "14386     19841          Bristol Palace Hotel        -1  44.40679    8.93620   \n",
            "35138     48622       Best Western City Hotel         0  44.40925    8.93546   \n",
            "34118     46980  Best Western Hotel Metropoli         0  44.40995    8.93501   \n",
            "12274     16954               NH Genova Plaza        -1  44.41079    8.93791   \n",
            "49601    432315    Old Port Genova Centro B&B        -1  44.41097    8.92867   \n",
            "\n",
            "         city country    state  county      suburb postcode  \\\n",
            "14386  Genova  Italia  Liguria  Genova    Portoria    16123   \n",
            "35138  Genova  Italia  Liguria  Genova    Portoria    16123   \n",
            "34118  Genova  Italia  Liguria  Genova   Maddalena    16123   \n",
            "12274  Genova  Italia  Liguria  Genova    Portoria    16122   \n",
            "49601  Genova  Italia  Liguria  Genova  Centro Est    16100   \n",
            "\n",
            "                      road house_number  distance_km  \n",
            "14386  Via Venti Settembre    227 rosso     0.192905  \n",
            "35138   Via San Sebastiano            6     0.255086  \n",
            "34118  Vico dei Migliorini          NaN     0.312697  \n",
            "12274   Via Martin Piaggio           11     0.507388  \n",
            "49601   Piazza Caricamento     65 rosso     0.583352  \n",
            "Skipping image at URL: https://i.travelapi.com/hotels/1000000/10000/7400/7354/50ce3a3d_b.jpg\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyM9LnSyumUMUWLLv/Ip3mGU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d0e85e3008f4c8bb99c846ec46f617d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f652beffd4c4fa6b244ee9c3191d7d8",
              "IPY_MODEL_a600dbd9b9c64c5abc8ae55f8b199aba",
              "IPY_MODEL_3925d9e177b84b65b585d211bfe1bd11"
            ],
            "layout": "IPY_MODEL_3b88434581724df19cbb00d9a6bda81f"
          }
        },
        "4f652beffd4c4fa6b244ee9c3191d7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4215e47d272d420aab7945db0597554f",
            "placeholder": "​",
            "style": "IPY_MODEL_a41e73ca1d784a11b296be4715b4a4fe",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a600dbd9b9c64c5abc8ae55f8b199aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98ea48888c2f4ee392864cd47ed39a9a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4def96e841f94ba3b7e9620af6c31459",
            "value": 3
          }
        },
        "3925d9e177b84b65b585d211bfe1bd11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51d97bd0273a45318d4dafed06a7a440",
            "placeholder": "​",
            "style": "IPY_MODEL_c48793cdfe6e4700a6c29b5d92526967",
            "value": " 3/3 [00:06&lt;00:00,  2.07s/it]"
          }
        },
        "3b88434581724df19cbb00d9a6bda81f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4215e47d272d420aab7945db0597554f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41e73ca1d784a11b296be4715b4a4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98ea48888c2f4ee392864cd47ed39a9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4def96e841f94ba3b7e9620af6c31459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51d97bd0273a45318d4dafed06a7a440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48793cdfe6e4700a6c29b5d92526967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}